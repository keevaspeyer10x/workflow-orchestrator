https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents

transcript from chat with jack

add a design phase

merge - including merging to a branch and rerunning all tests

do we create a PRD in a similar format to Thallow with screenshots for human review. what is best practice 

ultimately tool will need a front end for settings, document review and UI/UX review. Can I plug it in to vc code or something?

currently one shots everything. may makes sense to chunky it linked to context 

do we need to maintain a north star and perhaps updated PRD for context?

learnings need to have recommendations which are then implemented.

Do we need items like a North Start or the Manus Custom Instructions

Add a final stage - document - eg. not sure what it looks like, but update PRD, spec document, README files, set-up instructions etc. 

Might need to chunk the work at some stages - if complex enough

Design at the start, 

Do we make a formal test phase?


Start spinning up multiple agents - to massively accelerate what we'll do. 

Provde a summary on screen before asking for approval

I'd also always like to see a summary of the learnings and the feedback from the other AI models - at least how many issues they identified.

Are we checking if Loearnings implies new things for the ROADMAP?

Don't forget
- In my installation instructions recommend running with no checking

- At the end suggest committing changes if they haven't been

- Tidy up the repo - archive unnecessary file

Proactively add CI/CD tests on PR or merge - Code reviews, other things to think about? Should we putting CI/CD practices into place as part of this whole process. Should we be reviewing the workflow from a Expert CI/CD perspective?


# Done

Document at the end.

Should we have an AI critique the plan - or every step?

Need a link to the relevant files in the comments after each section before approve. Review Things.
